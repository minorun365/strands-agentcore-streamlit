from strands import Agent, tool
from bedrock_agentcore.runtime import BedrockAgentCoreApp
from bedrock_agentcore.memory import MemoryClient
from dotenv import load_dotenv
from mcp.client.streamable_http import streamablehttp_client
from strands.tools.mcp.mcp_client import MCPClient
from typing import AsyncGenerator, Any, Dict, Optional
import asyncio

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºç”¨ï¼‰
load_dotenv()

# Memoryé–¢é€£ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
memory_client = None
MEMORY_ID = None

def initialize_memory():
    """ãƒ¡ãƒ¢ãƒªã®åˆæœŸåŒ–ï¼ˆæ—¢å­˜ãƒ¡ãƒ¢ãƒªãŒã‚ã‚‹å ´åˆã¯å†åˆ©ç”¨ï¼‰"""
    global memory_client, MEMORY_ID
    
    if memory_client is None:
        try:
            memory_client = MemoryClient(region_name="us-west-2")
            
            # ã¾ãšæ—¢å­˜ã®ãƒ¡ãƒ¢ãƒªä¸€è¦§ã‚’å–å¾—ã—ã¦ç¢ºèª
            try:
                # æ—¢å­˜ãƒ¡ãƒ¢ãƒªãŒã‚ã‚‹å ´åˆã¯å†åˆ©ç”¨ï¼ˆãƒ‡ãƒ¢ã‚¢ãƒ—ãƒªã¨ã—ã¦ã‚·ãƒ³ãƒ—ãƒ«ï¼‰
                memories = memory_client.list_memories()
                existing_memory = None
                
                # ChatHistoryMemoryã¨ã„ã†åå‰ã®ãƒ¡ãƒ¢ãƒªã‚’æ¢ã™
                for memory in memories.get('memories', []):
                    if memory.get('name') == 'ChatHistoryMemory':
                        existing_memory = memory
                        break
                
                if existing_memory:
                    MEMORY_ID = existing_memory.get('id')
                    print(f"Memory found and reused with ID: {MEMORY_ID}")
                else:
                    # æ–°ã—ã„ãƒ¡ãƒ¢ãƒªã‚’ä½œæˆ
                    memory = memory_client.create_memory(
                        name="ChatHistoryMemory",
                        description="Chat history memory for demo app"
                    )
                    MEMORY_ID = memory.get('id')
                    print(f"New memory created with ID: {MEMORY_ID}")
                    
            except Exception as create_error:
                print(f"Memory operation failed: {create_error}")
                # ãƒ¡ãƒ¢ãƒªæ©Ÿèƒ½ãªã—ã§ã‚‚å‹•ä½œã‚’ç¶™ç¶š
                memory_client = None
                MEMORY_ID = None
                
        except Exception as client_error:
            print(f"MemoryClient initialization failed: {client_error}")
            memory_client = None
            MEMORY_ID = None

async def save_conversation_to_memory(session_id: str, user_message: str, assistant_response: str):
    """ä¼šè©±ã‚’AgentCore Memoryã«ä¿å­˜"""
    global memory_client, MEMORY_ID
    
    if memory_client and MEMORY_ID:
        try:
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿å­˜
            await memory_client.create_event_async(
                memory_id=MEMORY_ID,
                actor_id=f"user_{session_id}",
                session_id=session_id,
                messages=[(user_message, "USER")]
            )
            
            # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ä¿å­˜
            await memory_client.create_event_async(
                memory_id=MEMORY_ID,
                actor_id=f"user_{session_id}",
                session_id=session_id,
                messages=[(assistant_response, "ASSISTANT")]
            )
        except Exception as e:
            print(f"Memory save failed: {e}")

async def get_conversation_history(session_id: str, k: int = 5):
    """éå»ã®ä¼šè©±å±¥æ­´ã‚’å–å¾—"""
    global memory_client, MEMORY_ID
    
    if memory_client and MEMORY_ID:
        try:
            # æœ€è¿‘ã®kå›ã®ä¼šè©±ã‚’å–å¾—
            recent_turns = await memory_client.get_last_k_turns_async(
                memory_id=MEMORY_ID,
                actor_id=f"user_{session_id}",
                session_id=session_id,
                k=k
            )
            return recent_turns
        except Exception as e:
            print(f"Memory retrieval failed: {e}")
            return []
    return []

# MCPã‚µãƒ¼ãƒãƒ¼ã‚’è¨­å®š
streamable_http_mcp_client = MCPClient(
    lambda: streamablehttp_client("https://knowledge-mcp.global.api.aws")
)

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¨ã—ã¦è¦ªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ä¿æŒ
parent_stream_queue: Optional[asyncio.Queue] = None

# AWSã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ãƒ„ãƒ¼ãƒ«ã¨ã—ã¦å®šç¾©
@tool
async def aws_knowledge_agent(query: str) -> str:
    accumulated_response = ""
    
    with streamable_http_mcp_client:
        
        # AWSã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆ
        available_tools = streamable_http_mcp_client.list_tools_sync()
        
        aws_agent = Agent(
            model="us.anthropic.claude-3-7-sonnet-20250219-v1:0",
            tools=available_tools
        )
        
        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å›ç­”ã‚’å–å¾—
        async for event in aws_agent.stream_async(query):
            
            # ã¾ãšå³åº§ã«ã‚¤ãƒ™ãƒ³ãƒˆã‚’è¦ªã‚¹ãƒˆãƒªãƒ¼ãƒ ã«è»¢é€ï¼ˆãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ€§ç¢ºä¿ï¼‰
            if parent_stream_queue and isinstance(event, dict) and "event" in event:
                event_data = event["event"]
                
                # ãƒ„ãƒ¼ãƒ«ä½¿ç”¨é–‹å§‹ã‚’å³åº§ã«æ¤œå‡ºã—ã¦é€ä¿¡
                if "contentBlockStart" in event_data:
                    start_data = event_data["contentBlockStart"].get("start", {})
                    
                    if "toolUse" in start_data:
                        tool_info = start_data["toolUse"]
                        tool_name = tool_info.get("name", "unknown")
                        
                        # å³åº§ã«ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œé–‹å§‹ã‚’é€šçŸ¥
                        await parent_stream_queue.put({
                            "event": {
                                "subAgentProgress": {
                                    "message": f"ğŸ”§ ãƒ„ãƒ¼ãƒ«ã€Œ{tool_name}ã€ã‚’å®Ÿè¡Œä¸­",
                                    "stage": "tool_use",
                                    "tool_name": tool_name
                                }
                            }
                        })
                
                # ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ«ã‚¿ã‚’å‡¦ç†ï¼ˆãƒ„ãƒ¼ãƒ«å®Ÿè¡Œä¸­ã§ãªã„å ´åˆã®ã¿ï¼‰
                elif "contentBlockDelta" in event_data:
                    delta = event_data["contentBlockDelta"].get("delta", {})
                    
                    # ãƒ„ãƒ¼ãƒ«å…¥åŠ›ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                    if "toolUse" in delta:
                        continue
                        
                    if "text" in delta:
                        text = delta["text"]
                        accumulated_response += text
                        # ã‚µãƒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å³åº§ã«é€ä¿¡
                        await parent_stream_queue.put({
                            "event": {
                                "contentBlockDelta": {
                                    "delta": {
                                        "text": text
                                    }
                                }
                            }
                        })
                
                # ãã®ä»–ã®ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆmessageStopç­‰ï¼‰ã‚‚å³åº§ã«è»¢é€
                else:
                    await parent_stream_queue.put(event)
            
            elif parent_stream_queue and isinstance(event, str):
                # æ–‡å­—åˆ—ã‚¤ãƒ™ãƒ³ãƒˆã‚‚å³åº§ã«é€ä¿¡
                accumulated_response += event
                await parent_stream_queue.put({
                    "event": {
                        "contentBlockDelta": {
                            "delta": {
                                "text": event
                            }
                        }
                    }
                })
        
        # æœ€çµ‚çš„ãªçµæœã‚’è¦ªã‚¹ãƒˆãƒªãƒ¼ãƒ ã«é€ä¿¡
        if parent_stream_queue and accumulated_response:
            await parent_stream_queue.put({
                "event": {
                    "subAgentProgress": {
                        "message": "âœ… ã‚µãƒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒç›®çš„ã‚’å®Œäº†ã—ã¾ã—ãŸ",
                        "stage": "complete"
                    }
                }
            })

        # æœ€çµ‚çš„ãªå¿œç­”ã‚’è¿”ã™
        final_response = accumulated_response
        return final_response

# ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆï¼ˆsupervisorã¨ã—ã¦å‹•ä½œï¼‰
agent = Agent(
    model="us.anthropic.claude-3-7-sonnet-20250219-v1:0",
    tools=[aws_knowledge_agent],
    system_prompt="ã‚µãƒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€ŒAWSãƒã‚¹ã‚¿ãƒ¼ã€ã‚’æ´»ç”¨ã—ã¦ç°¡æ½”ã«å›ç­”ã—ã¦ã­"
)

# AgentCoreã‚’åˆæœŸåŒ–
app = BedrockAgentCoreApp()

# AgentCoreã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆé–¢æ•°ã‚’å®šç¾©
@app.entrypoint
async def invoke(payload: Dict[str, Any]) -> AsyncGenerator[Any, None]:
    global parent_stream_queue
    
    # ãƒ¡ãƒ¢ãƒªã®åˆæœŸåŒ–ï¼ˆåˆå›ã®ã¿å®Ÿè¡Œï¼‰
    initialize_memory()
    
    # AgentCore Runtimeå½¢å¼ã§ã®ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰å–å¾—
    input_data = payload.get("input", {})
    user_message = input_data.get("prompt", "")
    session_id = input_data.get("session_id", "default_session")
    
    # éå»ã®ä¼šè©±å±¥æ­´ã‚’å–å¾—ã—ã¦ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«è¿½åŠ 
    history = await get_conversation_history(session_id, k=3)
    if history:
        context = "éå»ã®ä¼šè©±å±¥æ­´:\n" + "\n".join([f"{msg['role']}: {msg['content']}" for msg in history]) + "\n\n"
        user_message = context + user_message
    
    # ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚­ãƒ¥ãƒ¼ã‚’åˆæœŸåŒ–
    parent_stream_queue = asyncio.Queue()
    
    try:
        # ä¸¡æ–¹ã®ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’çµ±åˆ
        agent_stream = agent.stream_async(user_message)
        
        async def merged_stream():
            # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¹ãƒˆãƒªãƒ¼ãƒ ã¨ã‚­ãƒ¥ãƒ¼ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’çµ±åˆ
            agent_task = asyncio.create_task(anext(agent_stream, None))
            queue_task = asyncio.create_task(parent_stream_queue.get()) if parent_stream_queue else None
            
            pending = {agent_task}
            if queue_task:
                pending.add(queue_task)
            
            while pending:
                done, pending = await asyncio.wait(pending, return_when=asyncio.FIRST_COMPLETED)
                
                for task in done:
                    if task == agent_task:
                        event = task.result()
                        if event is not None:
                            yield event
                            # æ¬¡ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¤ãƒ™ãƒ³ãƒˆã‚’å–å¾—
                            agent_task = asyncio.create_task(anext(agent_stream, None))
                            pending.add(agent_task)
                        else:
                            # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¹ãƒˆãƒªãƒ¼ãƒ å®Œäº†ã€ã‚­ãƒ¥ãƒ¼ã®ã¿å‡¦ç†ã‚’ç¶šã‘ã‚‹
                            agent_task = None
                    elif task == queue_task:
                        try:
                            event = task.result()
                            yield event
                            # æ¬¡ã®ã‚­ãƒ¥ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆã‚’å–å¾—
                            if parent_stream_queue:
                                queue_task = asyncio.create_task(parent_stream_queue.get())
                                pending.add(queue_task)
                            else:
                                queue_task = None
                        except asyncio.QueueEmpty:
                            pass
                        except Exception as e:
                            queue_task = None
                
                # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå®Œäº†ã—ã€ã‚­ãƒ¥ãƒ¼ãŒç©ºã«ãªã£ãŸã‚‰çµ‚äº†
                if agent_task is None and (parent_stream_queue is None or parent_stream_queue.empty()):
                    break
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è“„ç©ã™ã‚‹ãŸã‚ã®å¤‰æ•°
        accumulated_response = ""
        
        # çµ±åˆã•ã‚ŒãŸã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’yield
        async for event in merged_stream():
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã‚’è“„ç©
            if isinstance(event, dict) and "event" in event:
                event_data = event["event"]
                if "contentBlockDelta" in event_data:
                    delta = event_data["contentBlockDelta"].get("delta", {})
                    if "text" in delta:
                        accumulated_response += delta["text"]
            
            yield event
            
        # ä¼šè©±çµ‚äº†å¾Œã«ãƒ¡ãƒ¢ãƒªã«ä¿å­˜
        if accumulated_response:
            original_prompt = input_data.get("prompt", "")
            await save_conversation_to_memory(session_id, original_prompt, accumulated_response)
            
    except Exception as e:
        raise
    finally:
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        parent_stream_queue = None

# AgentCoreã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•
app.run()